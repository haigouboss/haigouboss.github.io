<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>DL | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="PyTorchPyTorch是一个python库，它主要提供了两个高级功能：  GPU加速的张量计算 构建在反向自动求导系统上的深度神经网络  1. 定义数据一般定义数据使用torch.Tensor ， tensor的意思是张量，是数字各种形式的总称 In [0]: 12345import torch# 可以是一个数x &#x3D; torch.tensor(666)print(x)  Out[0]: 1t">
<meta property="og:type" content="article">
<meta property="og:title" content="DL">
<meta property="og:url" content="http://example.com/2023/07/13/DL/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="PyTorchPyTorch是一个python库，它主要提供了两个高级功能：  GPU加速的张量计算 构建在反向自动求导系统上的深度神经网络  1. 定义数据一般定义数据使用torch.Tensor ， tensor的意思是张量，是数字各种形式的总称 In [0]: 12345import torch# 可以是一个数x &#x3D; torch.tensor(666)print(x)  Out[0]: 1t">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="c:\Users\11526\Desktop\%E4%B8%8B%E8%BD%BD.png">
<meta property="article:published_time" content="2023-07-13T07:15:24.000Z">
<meta property="article:modified_time" content="2023-07-13T07:46:02.529Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="c:\Users\11526\Desktop\%E4%B8%8B%E8%BD%BD.png">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-DL" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/07/13/DL/" class="article-date">
  <time class="dt-published" datetime="2023-07-13T07:15:24.000Z" itemprop="datePublished">2023-07-13</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      DL
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h2 id="PyTorch"><a href="#PyTorch" class="headerlink" title="PyTorch"></a>PyTorch</h2><p>PyTorch是一个python库，它主要提供了两个高级功能：</p>
<ul>
<li>GPU加速的张量计算</li>
<li>构建在反向自动求导系统上的深度神经网络</li>
</ul>
<h2 id="1-定义数据"><a href="#1-定义数据" class="headerlink" title="1. 定义数据"></a>1. 定义数据</h2><p>一般定义数据使用torch.Tensor ， tensor的意思是张量，是数字各种形式的总称</p>
<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import torch</span><br><span class="line"></span><br><span class="line"># 可以是一个数</span><br><span class="line">x = torch.tensor(666)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(666)</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 可以是一维数组（向量）</span><br><span class="line">x = torch.tensor([1,2,3,4,5,6])</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 2, 3, 4, 5, 6])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 可以是二维数组（矩阵）</span><br><span class="line">x = torch.ones(2,3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 1., 1.],</span><br><span class="line">        [1., 1., 1.]])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 可以是任意维度的数组（张量）</span><br><span class="line">x = torch.ones(2,3,4,5)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line">tensor([[[[1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.]],</span><br><span class="line"></span><br><span class="line">         [[1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.]],</span><br><span class="line"></span><br><span class="line">         [[1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.]]],</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        [[[1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.]],</span><br><span class="line"></span><br><span class="line">         [[1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.]],</span><br><span class="line"></span><br><span class="line">         [[1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.],</span><br><span class="line">          [1., 1., 1., 1., 1.]]]])</span><br></pre></td></tr></table></figure>

<p>Tensor支持各种各样类型的数据，包括：</p>
<p>torch.float32, torch.float64, torch.float16, torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64 。这里不过多描述。</p>
<p>创建Tensor有多种方法，包括：ones, zeros, eye, arange, linspace, rand, randn, normal, uniform, randperm, 使用的时候可以在线搜，下面主要通过代码展示。</p>
<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个空张量</span><br><span class="line"># 随机生成</span><br><span class="line">x = torch.empty(5,3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1.4178e-36, 0.0000e+00, 4.4842e-44],</span><br><span class="line">        [0.0000e+00,        nan, 0.0000e+00],</span><br><span class="line">        [1.0979e-05, 4.2008e-05, 2.1296e+23],</span><br><span class="line">        [1.0386e+21, 4.4160e-05, 1.0742e-05],</span><br><span class="line">        [2.6963e+23, 4.2421e-08, 3.4548e-09]])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个随机初始化的张量</span><br><span class="line">x = torch.rand(5,3)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0.3077, 0.0347, 0.3033],</span><br><span class="line">        [0.9099, 0.2716, 0.4310],</span><br><span class="line">        [0.8286, 0.3317, 0.0536],</span><br><span class="line">        [0.9529, 0.4905, 0.1403],</span><br><span class="line">        [0.6899, 0.8349, 0.4015]])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个全0的张量，里面的数据类型为 long</span><br><span class="line">x = torch.zeros(5,3,dtype=torch.long)</span><br><span class="line">print(x)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0],</span><br><span class="line">        [0, 0, 0]])</span><br></pre></td></tr></table></figure>



<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"># 基于现有的tensor，创建一个新tensor，</span><br><span class="line"># 从而可以利用原有的tensor的dtype，device，size之类的属性信息</span><br><span class="line">y = x.new_ones(5,3)   #tensor new_* 方法，利用原来tensor的dtype，device</span><br><span class="line">print(y)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1, 1, 1],</span><br><span class="line">        [1, 1, 1],</span><br><span class="line">        [1, 1, 1],</span><br><span class="line">        [1, 1, 1],</span><br><span class="line">        [1, 1, 1]])</span><br></pre></td></tr></table></figure>



<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">z = torch.randn_like(x, dtype=torch.float)    # 利用原来的tensor的大小，但是重新定义了dtype</span><br><span class="line">print(z)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">tensor([[ 1.4363, -2.1019,  0.4444],</span><br><span class="line">        [-0.4706,  0.7441, -0.4631],</span><br><span class="line">        [-1.3860, -1.8919,  1.8794],</span><br><span class="line">        [ 1.8617,  0.6469,  0.5235],</span><br><span class="line">        [-0.1271, -1.0755,  0.0359]])</span><br></pre></td></tr></table></figure>



<h2 id="2-定义操作"><a href="#2-定义操作" class="headerlink" title="2. 定义操作"></a>2. 定义操作</h2><p>凡是用Tensor进行各种运算的，都是Function</p>
<p>最终，还是需要用Tensor来进行计算的，计算无非是</p>
<ul>
<li>基本运算，加减乘除，求幂求余</li>
<li>布尔运算，大于小于，最大最小</li>
<li>线性运算，矩阵乘法，求模，求行列式</li>
</ul>
<p><strong>基本运算包括：</strong> abs&#x2F;sqrt&#x2F;div&#x2F;exp&#x2F;fmod&#x2F;pow ，及一些三角函数 cos&#x2F; sin&#x2F; asin&#x2F; atan2&#x2F; cosh，及 ceil&#x2F;round&#x2F;floor&#x2F;trunc 等具体在使用的时候可以百度一下</p>
<p><strong>布尔运算包括：</strong> gt&#x2F;lt&#x2F;ge&#x2F;le&#x2F;eq&#x2F;ne，topk, sort, max&#x2F;min</p>
<p><strong>线性计算包括：</strong> trace, diag, mm&#x2F;bmm，t，dot&#x2F;cross，inverse，svd 等</p>
<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 创建一个 2x4 的浮点型tensor</span><br><span class="line">m = torch.Tensor([[2., 5., 3., 7.],</span><br><span class="line">                  [4., 2., 1., 9.]])</span><br><span class="line"></span><br><span class="line">print(m.size(0), m.size(1), m.size(),m.type(), sep=&#x27; -- &#x27;)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">2 -- 4 -- torch.Size([2, 4]) -- torch.FloatTensor</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 返回 m 中元素的数量</span><br><span class="line">print(m.numel())</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">8</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 返回 第0行，第2列的数</span><br><span class="line">print(m[0][2])</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor(3.)</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 返回 第1列的全部元素</span><br><span class="line">print(m[:, 1])</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([5., 2.])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 返回 第0行的全部元素</span><br><span class="line">print(m[0, :])</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([2., 5., 3., 7.])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># Create tensor of numbers from 1 to 5</span><br><span class="line"># 注意这里结果是1到4，没有5</span><br><span class="line">#</span><br><span class="line">v = torch.arange(1., 5.)</span><br><span class="line">print(v)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([1, 2, 3, 4])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># Scalar product  </span><br><span class="line"># 向量点乘，这里要求</span><br><span class="line">m @ v</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([49., 47.])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Calculated by 1*2 + 2*5 + 3*3 + 4*7</span><br><span class="line">m[[0], :] @ v</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([49.])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># Add a random tensor of size 2x4 to m</span><br><span class="line">m + torch.rand(2, 4)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[2.2495, 5.7699, 3.3819, 7.0271],</span><br><span class="line">        [4.4853, 2.1948, 1.8039, 9.2615]])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 转置，由 2x4 变为 4x2</span><br><span class="line">print(m.t())</span><br><span class="line"></span><br><span class="line"># 使用 transpose 也可以达到相同的效果，具体使用方法可以百度</span><br><span class="line">print(m.transpose(0, 1))</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">tensor([[2., 4.],</span><br><span class="line">        [5., 2.],</span><br><span class="line">        [3., 1.],</span><br><span class="line">        [7., 9.]])</span><br><span class="line">tensor([[2., 4.],</span><br><span class="line">        [5., 2.],</span><br><span class="line">        [3., 1.],</span><br><span class="line">        [7., 9.]])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># returns a 1D tensor of steps equally spaced points between start=3, end=8 and steps=20</span><br><span class="line">torch.linspace(3, 8, 20)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">tensor([3.0000, 3.2632, 3.5263, 3.7895, 4.0526, 4.3158, 4.5789, 4.8421, 5.1053,</span><br><span class="line">        5.3684, 5.6316, 5.8947, 6.1579, 6.4211, 6.6842, 6.9474, 7.2105, 7.4737,</span><br><span class="line">        7.7368, 8.0000])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from matplotlib import pyplot as plt</span><br><span class="line"></span><br><span class="line"># matlabplotlib 只能显示numpy类型的数据，下面展示了转换数据类型，然后显示</span><br><span class="line"># 注意 randn 是生成均值为 0， 方差为 1 的随机数</span><br><span class="line"># 下面是生成 1000 个随机数，并按照 100 个 bin 统计直方图</span><br><span class="line">plt.hist(torch.randn(1000).numpy(), 100);</span><br></pre></td></tr></table></figure>

<p><img src="C:\Users\11526\Desktop\下载.png" alt="下载"></p>
<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 当数据非常非常多的时候，正态分布会体现的非常明显</span><br><span class="line">plt.hist(torch.randn(10**6).numpy(), 100);</span><br><span class="line">1000000</span><br></pre></td></tr></table></figure>

<p>![下载 (1)](C:\Users\11526\Desktop\下载 (1).png)</p>
<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># 创建两个 1x4 的tensor</span><br><span class="line">a = torch.Tensor([[1, 2, 3, 4]])</span><br><span class="line">b = torch.Tensor([[5, 6, 7, 8]])</span><br><span class="line"></span><br><span class="line"># 在 0 方向拼接 （即在 Y 方各上拼接）, 会得到 2x4 的矩阵</span><br><span class="line">print( torch.cat((a,b), 0))</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 2., 3., 4.],</span><br><span class="line">        [5., 6., 7., 8.]])</span><br></pre></td></tr></table></figure>

<p>In [0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 在 1 方向拼接 （即在 X 方各上拼接）, 会得到 1x8 的矩阵</span><br><span class="line">print( torch.cat((a,b), 1))</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">tensor([[1., 2., 3., 4., 5., 6., 7., 8.]])</span><br></pre></td></tr></table></figure>
      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/07/13/DL/" data-id="clk0uji300000o4uof1nr9f5z" data-title="DL" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2023/07/13/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/07/13/DL/">DL</a>
          </li>
        
          <li>
            <a href="/2023/07/13/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>