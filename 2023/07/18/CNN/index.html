<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>CNN | Hexo</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="卷积神经网络（CNN）一、使用CNN对MNIST数据集分类深度卷积神经网络中，有如下特性  很多层: compositionality：深度卷积神经网络通常由多个卷积层和全连接层组成。通过堆叠多个层，网络能够逐渐学习到更高级别的抽象特征表示。每一层的输出作为下一层的输入，层与层之间的组合性使得网络能够建立复杂的特征表达和模式识别能力。 卷积: locality + stationarity of">
<meta property="og:type" content="article">
<meta property="og:title" content="CNN">
<meta property="og:url" content="http://example.com/2023/07/18/CNN/index.html">
<meta property="og:site_name" content="Hexo">
<meta property="og:description" content="卷积神经网络（CNN）一、使用CNN对MNIST数据集分类深度卷积神经网络中，有如下特性  很多层: compositionality：深度卷积神经网络通常由多个卷积层和全连接层组成。通过堆叠多个层，网络能够逐渐学习到更高级别的抽象特征表示。每一层的输出作为下一层的输入，层与层之间的组合性使得网络能够建立复杂的特征表达和模式识别能力。 卷积: locality + stationarity of">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://camo.githubusercontent.com/9c01c772a1597251f5722e32bc9dcfd28fd5a16b1b14ca943fb6af3ef3050ae3/687474703a2f2f7079746f7263686368696e612e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f31322f636966617231302e706e67">
<meta property="article:published_time" content="2023-07-18T06:32:03.000Z">
<meta property="article:modified_time" content="2023-07-21T13:30:36.477Z">
<meta property="article:author" content="John Doe">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://camo.githubusercontent.com/9c01c772a1597251f5722e32bc9dcfd28fd5a16b1b14ca943fb6af3ef3050ae3/687474703a2f2f7079746f7263686368696e612e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f31322f636966617231302e706e67">
  
    <link rel="alternate" href="/atom.xml" title="Hexo" type="application/atom+xml">
  
  
    <link rel="shortcut icon" href="/favicon.png">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
  
<meta name="generator" content="Hexo 6.3.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">Hexo</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"><span class="fa fa-bars"></span></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        
          <a class="nav-icon" href="/atom.xml" title="RSS Feed"><span class="fa fa-rss"></span></a>
        
        <a class="nav-icon nav-search-btn" title="Search"><span class="fa fa-search"></span></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://example.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-CNN" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2023/07/18/CNN/" class="article-date">
  <time class="dt-published" datetime="2023-07-18T06:32:03.000Z" itemprop="datePublished">2023-07-18</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      CNN
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <h1 id="卷积神经网络（CNN）"><a href="#卷积神经网络（CNN）" class="headerlink" title="卷积神经网络（CNN）"></a>卷积神经网络（CNN）</h1><h2 id="一、使用CNN对MNIST数据集分类"><a href="#一、使用CNN对MNIST数据集分类" class="headerlink" title="一、使用CNN对MNIST数据集分类"></a>一、使用CNN对MNIST数据集分类</h2><p>深度卷积神经网络中，有如下特性</p>
<ul>
<li>很多层: compositionality：深度卷积神经网络通常由多个卷积层和全连接层组成。通过堆叠多个层，网络能够逐渐学习到更高级别的抽象特征表示。每一层的输出作为下一层的输入，层与层之间的组合性使得网络能够建立复杂的特征表达和模式识别能力。</li>
<li>卷积: locality + stationarity of images：卷积层是深度卷积神经网络的核心。卷积操作通过滑动卷积核在输入数据上提取局部特征，利用局部连接性和权重共享的方式，捕捉输入数据的局部模式和特征。卷积层利用图像数据的局部性和图像在空间上的平移不变性，使网络能够有效地学习到图像的空间结构和位置信息。</li>
<li>池化: Invariance of object class to translations：池化层是用于下采样和保持局部不变性的操作。通过对特征图的局部区域进行汇聚，池化层可以减小特征图的尺寸，同时保持重要特征的不变性。池化层使得网络对输入数据的轻微平移、缩放等变化具有一定的不变性，使得网络能够对目标类别具有一定的平移不变性。</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"><span class="keyword">from</span> torchvision <span class="keyword">import</span> datasets, transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy</span><br><span class="line"></span><br><span class="line"><span class="comment"># 一个函数，用来计算模型中有多少参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_n_params</span>(<span class="params">model</span>):</span><br><span class="line">    np=<span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> p <span class="keyword">in</span> <span class="built_in">list</span>(model.parameters()):</span><br><span class="line">        np += p.nelement()</span><br><span class="line">    <span class="keyword">return</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用GPU训练，可以在菜单 &quot;代码执行工具&quot; -&gt; &quot;更改运行时类型&quot; 里进行设置</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br></pre></td></tr></table></figure>

<h3 id="1-加载数据"><a href="#1-加载数据" class="headerlink" title="1.加载数据"></a>1.加载数据</h3><p>PyTorch里包含了 MNIST， CIFAR10 等常用数据集，调用 torchvision.datasets 即可把这些数据由远程下载到本地，下面给出MNIST的使用方法：</p>
<p>torchvision.datasets.MNIST(root, train&#x3D;True, transform&#x3D;None, target_transform&#x3D;None, download&#x3D;False)</p>
<ul>
<li>root 为数据集下载到本地后的根目录，包括 training.pt 和 test.pt 文件</li>
<li>train，如果设置为True，从training.pt创建数据集，否则从test.pt创建。</li>
<li>download，如果设置为True, 从互联网下载数据并放到root文件夹下</li>
<li>transform, 一种函数或变换，输入PIL图片，返回变换之后的数据。</li>
<li>target_transform 一种函数或变换，输入目标，进行变换。</li>
</ul>
<p>另外值得注意的是，DataLoader是一个比较重要的类，提供的常用操作有：batch_size(每个batch的大小), shuffle(是否进行随机打乱顺序的操作), num_workers(加载数据的时候使用几个子进程)</p>
<p>In[0]：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">input_size  = <span class="number">28</span>*<span class="number">28</span>   <span class="comment"># MNIST上的图像尺寸是 28x28</span></span><br><span class="line">output_size = <span class="number">10</span>      <span class="comment"># 类别为 0 到 9 的数字，因此为十类</span></span><br><span class="line"></span><br><span class="line">train_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>, download=<span class="literal">True</span>,</span><br><span class="line">        transform=transforms.Compose(</span><br><span class="line">            [transforms.ToTensor(),</span><br><span class="line">             transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])),</span><br><span class="line">    batch_size=<span class="number">64</span>, shuffle=<span class="literal">True</span>)</span><br><span class="line"></span><br><span class="line">test_loader = torch.utils.data.DataLoader(</span><br><span class="line">    datasets.MNIST(<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, transform=transforms.Compose([</span><br><span class="line">             transforms.ToTensor(),</span><br><span class="line">             transforms.Normalize((<span class="number">0.1307</span>,), (<span class="number">0.3081</span>,))])),</span><br><span class="line">    batch_size=<span class="number">1000</span>, shuffle=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>

<p>Output[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">9912422</span>/<span class="number">9912422</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">157760433.05</span>it/s]Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz</span><br><span class="line">Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">28881</span>/<span class="number">28881</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">22202289.92</span>it/s]</span><br><span class="line">Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw</span><br><span class="line"></span><br><span class="line">Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz</span><br><span class="line">Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">1648877</span>/<span class="number">1648877</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">85069453.94</span>it/s]Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz</span><br><span class="line">Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">4542</span>/<span class="number">4542</span> [<span class="number">00</span>:<span class="number">00</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">3282875.89</span>it/s]</span><br><span class="line">Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw</span><br></pre></td></tr></table></figure>

<p><strong>显示数据集中的部分图像</strong></p>
<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">5</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">20</span>):</span><br><span class="line">    plt.subplot(<span class="number">4</span>, <span class="number">5</span>, i + <span class="number">1</span>)</span><br><span class="line">    image, _ = train_loader.dataset.__getitem__(i)</span><br><span class="line">    plt.imshow(image.squeeze().numpy(),<span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>);</span><br><span class="line">     </span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>Output[]:</p>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAboAAAEeCAYAAAD8etB9AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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%0AXehERMRr/w+vLFuBlmg8HAAAAABJRU5ErkJggg==" alt="img"></p>
<h3 id="2-创建网络"><a href="#2-创建网络" class="headerlink" title="2. 创建网络"></a>2. 创建网络</h3><p>定义网络时，需要继承nn.Module，并实现它的forward方法，把网络中具有可学习参数的层放在构造函数__init__中。</p>
<p>只要在<strong>nn.Module</strong>的子类中定义了<strong>forward</strong>函数，**backward函数就会自动被实现(利用autograd)**。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">FC2Layer</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, n_hidden, output_size</span>):</span><br><span class="line">        <span class="comment"># nn.Module子类的函数必须在构造函数中执行父类的构造函数</span></span><br><span class="line">        <span class="comment"># 下式等价于nn.Module.__init__(self)        </span></span><br><span class="line">        <span class="built_in">super</span>(FC2Layer, self).__init__()</span><br><span class="line">        self.input_size = input_size</span><br><span class="line">        <span class="comment"># 这里直接用 Sequential 就定义了网络，注意要和下面 CNN 的代码区分开</span></span><br><span class="line">        self.network = nn.Sequential(</span><br><span class="line">            nn.Linear(input_size, n_hidden), </span><br><span class="line">            nn.ReLU(), </span><br><span class="line">            nn.Linear(n_hidden, n_hidden), </span><br><span class="line">            nn.ReLU(), </span><br><span class="line">            nn.Linear(n_hidden, output_size), </span><br><span class="line">            nn.LogSoftmax(dim=<span class="number">1</span>)</span><br><span class="line">        )</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        <span class="comment"># view一般出现在model类的forward函数中，用于改变输入或输出的形状</span></span><br><span class="line">        <span class="comment"># x.view(-1, self.input_size) 的意思是多维的数据展成二维</span></span><br><span class="line">        <span class="comment"># 代码指定二维数据的列数为 input_size=784，行数 -1 表示我们不想算，电脑会自己计算对应的数字</span></span><br><span class="line">        <span class="comment"># 在 DataLoader 部分，我们可以看到 batch_size 是64，所以得到 x 的行数是64</span></span><br><span class="line">        <span class="comment"># 大家可以加一行代码：print(x.cpu().numpy().shape)</span></span><br><span class="line">        <span class="comment"># 训练过程中，就会看到 (64, 784) 的输出，和我们的预期是一致的</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># forward 函数的作用是，指定网络的运行过程，这个全连接网络可能看不到意义，</span></span><br><span class="line">        <span class="comment"># 下面的CNN网络可以看出 forward 的作用。</span></span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.input_size)</span><br><span class="line">        <span class="keyword">return</span> self.network(x)</span><br><span class="line">    </span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">CNN</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, input_size, n_feature, output_size</span>):</span><br><span class="line">        <span class="comment"># 执行父类的构造函数，所有的网络都要这么写</span></span><br><span class="line">        <span class="built_in">super</span>(CNN, self).__init__()</span><br><span class="line">        <span class="comment"># 下面是网络里典型结构的一些定义，一般就是卷积和全连接</span></span><br><span class="line">        <span class="comment"># 池化、ReLU一类的不用在这里定义</span></span><br><span class="line">        self.n_feature = n_feature</span><br><span class="line">        self.conv1 = nn.Conv2d(in_channels=<span class="number">1</span>, out_channels=n_feature, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(n_feature, n_feature, kernel_size=<span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(n_feature*<span class="number">4</span>*<span class="number">4</span>, <span class="number">50</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">50</span>, <span class="number">10</span>)    </span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 下面的 forward 函数，定义了网络的结构，按照一定顺序，把上面构建的一些结构组织起来</span></span><br><span class="line">    <span class="comment"># 意思就是，conv1, conv2 等等的，可以多次重用</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, verbose=<span class="literal">False</span></span>):</span><br><span class="line">        x = self.conv1(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.max_pool2d(x, kernel_size=<span class="number">2</span>)</span><br><span class="line">        x = self.conv2(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = F.max_pool2d(x, kernel_size=<span class="number">2</span>)</span><br><span class="line">        x = x.view(-<span class="number">1</span>, self.n_feature*<span class="number">4</span>*<span class="number">4</span>)</span><br><span class="line">        x = self.fc1(x)</span><br><span class="line">        x = F.relu(x)</span><br><span class="line">        x = self.fc2(x)</span><br><span class="line">        x = F.log_softmax(x, dim=<span class="number">1</span>)</span><br><span class="line">        <span class="keyword">return</span> x</span><br></pre></td></tr></table></figure>

<p>该卷积神经网络包含两个卷积层和两个全连接层，每个卷积层中，网络使用5x5大小的卷积核对输入进行卷积操作，以提取图像中的特征。卷积核的参数由网络自动学习，用于对输入数据进行特征提取和表示。在前向传播函数 <code>forward</code> 中，网络的结构如下：</p>
<ol>
<li>输入通过第一个卷积层 <code>self.conv1</code> 进行卷积操作，然后经过ReLU激活函数。</li>
<li>经过最大池化操作 <code>F.max_pool2d</code>（池化核大小为2x2）进行下采样。</li>
<li>输入再经过第二个卷积层 <code>self.conv2</code> 进行卷积操作，然后再经过ReLU激活函数。</li>
<li>再次经过最大池化操作 <code>F.max_pool2d</code> 进行下采样。</li>
<li>将特征图展平为一维向量，使用 <code>x.view</code> 将其变换为形状为<code>(-1, n_feature*4*4)</code>的张量。</li>
<li>输入通过第一个全连接层 <code>self.fc1</code> 进行线性变换，并经过ReLU激活函数。</li>
<li>输入通过第二个全连接层 <code>self.fc2</code> 进行线性变换。</li>
<li>最后，通过LogSoftmax函数 <code>F.log_softmax</code> 进行分类结果的计算。</li>
</ol>
<p>定义训练和测试函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 训练函数 SGD</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train</span>(<span class="params">model</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="comment"># 主里从train_loader里，64个样本一个batch为单位提取样本进行训练</span></span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        <span class="comment"># 把数据送到GPU中</span></span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.nll_loss(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train: [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test</span>(<span class="params">model</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        <span class="comment"># 把数据送到GPU中</span></span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        <span class="comment"># 把数据送入模型，得到预测结果</span></span><br><span class="line">        output = model(data)</span><br><span class="line">        <span class="comment"># 计算本次batch的损失，并加到 test_loss 中</span></span><br><span class="line">        test_loss += F.nll_loss(output, target, reduction=<span class="string">&#x27;sum&#x27;</span>).item()</span><br><span class="line">        <span class="comment"># get the index of the max log-probability，最后一层输出10个数，</span></span><br><span class="line">        <span class="comment"># 值最大的那个即对应着分类结果，然后把分类结果保存在 pred 里</span></span><br><span class="line">        pred = output.data.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>]</span><br><span class="line">        <span class="comment"># 将 pred 与 target 相比，得到正确预测结果的数量，并加到 correct 中</span></span><br><span class="line">        <span class="comment"># 这里需要注意一下 view_as ，意思是把 target 变成维度和 pred 一样的意思                                                </span></span><br><span class="line">        correct += pred.eq(target.data.view_as(pred)).cpu().<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    accuracy = <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        accuracy))</span><br></pre></td></tr></table></figure>

<h3 id="3-在小型全连接网络上训练（Fully-connected-network）"><a href="#3-在小型全连接网络上训练（Fully-connected-network）" class="headerlink" title="3. 在小型全连接网络上训练（Fully-connected network）"></a>3. 在小型全连接网络上训练（Fully-connected network）</h3><p>对于FC2Layer（全连接网络）：</p>
<ul>
<li>输入层到第一个隐藏层之间的连接有 <code>(input_size + 1) * n_hidden</code> 个参数，其中 <code>+1</code> 是因为有一个偏置项。</li>
<li>从第一个隐藏层到第二个隐藏层之间的连接有<code>(n_hidden + 1) * n_hidden</code> 个参数，包括偏置项。</li>
<li>第二个隐藏层到输出层之间的连接有 <code>(n_hidden + 1) * output_size</code> 个参数，同样也包括偏置项。</li>
</ul>
<p>因此，FC2Layer网络的总参数数量为 <code>(input_size + 1) * n_hidden + (n_hidden + 1) * n_hidden+(n_hidden + 1) * output_size=6442</code>。</p>
<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">n_hidden = <span class="number">8</span> <span class="comment"># number of hidden units</span></span><br><span class="line"></span><br><span class="line">model_fnn = FC2Layer(input_size, n_hidden, output_size)</span><br><span class="line">model_fnn.to(device)</span><br><span class="line">optimizer = optim.SGD(model_fnn.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of parameters: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(get_n_params(model_fnn)))</span><br><span class="line"></span><br><span class="line">train(model_fnn)</span><br><span class="line">test(model_fnn)</span><br></pre></td></tr></table></figure>

<p>Output[]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Number of parameters: <span class="number">6442</span></span><br><span class="line">Train: [<span class="number">0</span>/<span class="number">60000</span> (<span class="number">0</span>%)]	Loss: <span class="number">2.293928</span></span><br><span class="line">Train: [<span class="number">6400</span>/<span class="number">60000</span> (<span class="number">11</span>%)]	Loss: <span class="number">1.726802</span></span><br><span class="line">Train: [<span class="number">12800</span>/<span class="number">60000</span> (<span class="number">21</span>%)]	Loss: <span class="number">0.999539</span></span><br><span class="line">Train: [<span class="number">19200</span>/<span class="number">60000</span> (<span class="number">32</span>%)]	Loss: <span class="number">0.698048</span></span><br><span class="line">Train: [<span class="number">25600</span>/<span class="number">60000</span> (<span class="number">43</span>%)]	Loss: <span class="number">0.694266</span></span><br><span class="line">Train: [<span class="number">32000</span>/<span class="number">60000</span> (<span class="number">53</span>%)]	Loss: <span class="number">0.517686</span></span><br><span class="line">Train: [<span class="number">38400</span>/<span class="number">60000</span> (<span class="number">64</span>%)]	Loss: <span class="number">0.550588</span></span><br><span class="line">Train: [<span class="number">44800</span>/<span class="number">60000</span> (<span class="number">75</span>%)]	Loss: <span class="number">0.574714</span></span><br><span class="line">Train: [<span class="number">51200</span>/<span class="number">60000</span> (<span class="number">85</span>%)]	Loss: <span class="number">0.451625</span></span><br><span class="line">Train: [<span class="number">57600</span>/<span class="number">60000</span> (<span class="number">96</span>%)]	Loss: <span class="number">0.646509</span></span><br><span class="line"></span><br><span class="line">Test <span class="built_in">set</span>: Average loss: <span class="number">0.4263</span>, Accuracy: <span class="number">8781</span>/<span class="number">10000</span> (<span class="number">88</span>%)</span><br></pre></td></tr></table></figure>



<h3 id="4-在卷积神经网络上训练"><a href="#4-在卷积神经网络上训练" class="headerlink" title="4. 在卷积神经网络上训练"></a>4. 在卷积神经网络上训练</h3><p>对于CNN（卷积神经网络）：</p>
<ul>
<li>第一个卷积层 <code>self.conv1</code> 的卷积核数量为 <code>n_feature</code>，每个卷积核的参数数量是 <code>(1 * 5 * 5 + 1) * n_feature</code>，其中 <code>1 * 5 * 5</code> 是卷积核的大小加上一个偏置项。</li>
<li>第二个卷积层 <code>self.conv2</code> 的卷积核数量仍然是 <code>n_feature</code>，每个卷积核的参数数量是 <code>(n_feature * 5 * 5 + 1) * n_feature</code>。</li>
<li>第一个全连接层 <code>self.fc1</code> 的参数数量为 <code>(n_feature * 4 * 4 + 1) * 50</code>，其中 <code>n_feature * 4 * 4</code> 是通过池化层后特征图的大小。</li>
<li>第二个全连接层 <code>self.fc2</code> 的参数数量为 <code>(50 + 1) * 10</code>。</li>
</ul>
<p>因此，CNN网络的总参数数量为 <code>(1 * 5 * 5 + 1) * n_feature + (n_feature * 5 * 5 + 1) * n_feature + (n_feature * 4 * 4 + 1) * 50 + (50 + 1) * 10=6422</code></p>
<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># Training settings </span></span><br><span class="line">n_features = <span class="number">6</span> <span class="comment"># number of feature maps   卷积核的个数即生成的feature map个数</span></span><br><span class="line"></span><br><span class="line">model_cnn = CNN(input_size, n_features, output_size)</span><br><span class="line">model_cnn.to(device)</span><br><span class="line">optimizer = optim.SGD(model_cnn.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of parameters: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(get_n_params(model_cnn)))</span><br><span class="line"></span><br><span class="line">train(model_cnn)</span><br><span class="line">test(model_cnn)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Number of parameters: <span class="number">6422</span></span><br><span class="line">Train: [<span class="number">0</span>/<span class="number">60000</span> (<span class="number">0</span>%)]	Loss: <span class="number">2.301901</span></span><br><span class="line">Train: [<span class="number">6400</span>/<span class="number">60000</span> (<span class="number">11</span>%)]	Loss: <span class="number">2.188120</span></span><br><span class="line">Train: [<span class="number">12800</span>/<span class="number">60000</span> (<span class="number">21</span>%)]	Loss: <span class="number">0.936976</span></span><br><span class="line">Train: [<span class="number">19200</span>/<span class="number">60000</span> (<span class="number">32</span>%)]	Loss: <span class="number">0.378412</span></span><br><span class="line">Train: [<span class="number">25600</span>/<span class="number">60000</span> (<span class="number">43</span>%)]	Loss: <span class="number">0.247807</span></span><br><span class="line">Train: [<span class="number">32000</span>/<span class="number">60000</span> (<span class="number">53</span>%)]	Loss: <span class="number">0.467011</span></span><br><span class="line">Train: [<span class="number">38400</span>/<span class="number">60000</span> (<span class="number">64</span>%)]	Loss: <span class="number">0.386442</span></span><br><span class="line">Train: [<span class="number">44800</span>/<span class="number">60000</span> (<span class="number">75</span>%)]	Loss: <span class="number">0.350129</span></span><br><span class="line">Train: [<span class="number">51200</span>/<span class="number">60000</span> (<span class="number">85</span>%)]	Loss: <span class="number">0.213113</span></span><br><span class="line">Train: [<span class="number">57600</span>/<span class="number">60000</span> (<span class="number">96</span>%)]	Loss: <span class="number">0.131443</span></span><br><span class="line"></span><br><span class="line">Test <span class="built_in">set</span>: Average loss: <span class="number">0.2149</span>, Accuracy: <span class="number">9341</span>/<span class="number">10000</span> (<span class="number">93</span>%)</span><br></pre></td></tr></table></figure>

<h3 id="5-打乱像素顺序再次在两个网络上训练与测试"><a href="#5-打乱像素顺序再次在两个网络上训练与测试" class="headerlink" title="5.打乱像素顺序再次在两个网络上训练与测试"></a>5.打乱像素顺序再次在两个网络上训练与测试</h3><p>考虑到CNN在卷积与池化上的优良特性，如果我们把图像中的像素打乱顺序，这样 卷积 和 池化 就难以发挥作用了，为了验证这个想法，我们把图像中的像素打乱顺序再试试。</p>
<p>首先下面代码展示随机打乱像素顺序后，图像的形态：</p>
<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 这里解释一下 torch.randperm 函数，给定参数n，返回一个从0到n-1的随机整数排列</span></span><br><span class="line">perm = torch.randperm(<span class="number">784</span>)</span><br><span class="line">plt.figure(figsize=(<span class="number">8</span>, <span class="number">4</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):</span><br><span class="line">    image, _ = train_loader.dataset.__getitem__(i)</span><br><span class="line">    <span class="comment"># permute pixels</span></span><br><span class="line">    image_perm = image.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>).clone()</span><br><span class="line">    image_perm = image_perm[:, perm]</span><br><span class="line">    image_perm = image_perm.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    plt.subplot(<span class="number">4</span>, <span class="number">5</span>, i + <span class="number">1</span>)</span><br><span class="line">    plt.imshow(image.squeeze().numpy(), <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br><span class="line">    plt.subplot(<span class="number">4</span>, <span class="number">5</span>, i + <span class="number">11</span>)</span><br><span class="line">    plt.imshow(image_perm.squeeze().numpy(), <span class="string">&#x27;gray&#x27;</span>)</span><br><span class="line">    plt.axis(<span class="string">&#x27;off&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAa8AAADnCAYAAACpF9m0AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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" alt="img"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"><span class="comment"># 对每个 batch 里的数据，打乱像素顺序的函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">perm_pixel</span>(<span class="params">data, perm</span>):</span><br><span class="line">    <span class="comment"># 转化为二维矩阵</span></span><br><span class="line">    data_new = data.view(-<span class="number">1</span>, <span class="number">28</span>*<span class="number">28</span>)</span><br><span class="line">    <span class="comment"># 打乱像素顺序</span></span><br><span class="line">    data_new = data_new[:, perm]</span><br><span class="line">    <span class="comment"># 恢复为原来4维的 tensor</span></span><br><span class="line">    data_new = data_new.view(-<span class="number">1</span>, <span class="number">1</span>, <span class="number">28</span>, <span class="number">28</span>)</span><br><span class="line">    <span class="keyword">return</span> data_new</span><br><span class="line"></span><br><span class="line"><span class="comment"># 训练函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_perm</span>(<span class="params">model, perm</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    <span class="keyword">for</span> batch_idx, (data, target) <span class="keyword">in</span> <span class="built_in">enumerate</span>(train_loader):</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line">        <span class="comment"># 像素打乱顺序</span></span><br><span class="line">        data = perm_pixel(data, perm)</span><br><span class="line"></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        output = model(data)</span><br><span class="line">        loss = F.nll_loss(output, target)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="keyword">if</span> batch_idx % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Train: [&#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)]\tLoss: &#123;:.6f&#125;&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">                batch_idx * <span class="built_in">len</span>(data), <span class="built_in">len</span>(train_loader.dataset),</span><br><span class="line">                <span class="number">100.</span> * batch_idx / <span class="built_in">len</span>(train_loader), loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="comment"># 测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">test_perm</span>(<span class="params">model, perm</span>):</span><br><span class="line">    model.<span class="built_in">eval</span>()</span><br><span class="line">    test_loss = <span class="number">0</span></span><br><span class="line">    correct = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> data, target <span class="keyword">in</span> test_loader:</span><br><span class="line">        data, target = data.to(device), target.to(device)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 像素打乱顺序</span></span><br><span class="line">        data = perm_pixel(data, perm)</span><br><span class="line"></span><br><span class="line">        output = model(data)</span><br><span class="line">        test_loss += F.nll_loss(output, target, reduction=<span class="string">&#x27;sum&#x27;</span>).item()</span><br><span class="line">        pred = output.data.<span class="built_in">max</span>(<span class="number">1</span>, keepdim=<span class="literal">True</span>)[<span class="number">1</span>]                                            </span><br><span class="line">        correct += pred.eq(target.data.view_as(pred)).cpu().<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line">    test_loss /= <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    accuracy = <span class="number">100.</span> * correct / <span class="built_in">len</span>(test_loader.dataset)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;\nTest set: Average loss: &#123;:.4f&#125;, Accuracy: &#123;&#125;/&#123;&#125; (&#123;:.0f&#125;%)\n&#x27;</span>.<span class="built_in">format</span>(</span><br><span class="line">        test_loss, correct, <span class="built_in">len</span>(test_loader.dataset),</span><br><span class="line">        accuracy))</span><br></pre></td></tr></table></figure>

<p>在全连接网络上训练与测试：</p>
<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">perm = torch.randperm(<span class="number">784</span>)</span><br><span class="line">n_hidden = <span class="number">8</span> <span class="comment"># number of hidden units</span></span><br><span class="line"></span><br><span class="line">model_fnn = FC2Layer(input_size, n_hidden, output_size)</span><br><span class="line">model_fnn.to(device)</span><br><span class="line">optimizer = optim.SGD(model_fnn.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of parameters: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(get_n_params(model_fnn)))</span><br><span class="line"></span><br><span class="line">train_perm(model_fnn, perm)</span><br><span class="line">test_perm(model_fnn, perm)</span><br></pre></td></tr></table></figure>

<p>Out[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Number of parameters: <span class="number">6442</span></span><br><span class="line">Train: [<span class="number">0</span>/<span class="number">60000</span> (<span class="number">0</span>%)]	Loss: <span class="number">2.264858</span></span><br><span class="line">Train: [<span class="number">6400</span>/<span class="number">60000</span> (<span class="number">11</span>%)]	Loss: <span class="number">2.041490</span></span><br><span class="line">Train: [<span class="number">12800</span>/<span class="number">60000</span> (<span class="number">21</span>%)]	Loss: <span class="number">1.552290</span></span><br><span class="line">Train: [<span class="number">19200</span>/<span class="number">60000</span> (<span class="number">32</span>%)]	Loss: <span class="number">1.093537</span></span><br><span class="line">Train: [<span class="number">25600</span>/<span class="number">60000</span> (<span class="number">43</span>%)]	Loss: <span class="number">0.799383</span></span><br><span class="line">Train: [<span class="number">32000</span>/<span class="number">60000</span> (<span class="number">53</span>%)]	Loss: <span class="number">0.847221</span></span><br><span class="line">Train: [<span class="number">38400</span>/<span class="number">60000</span> (<span class="number">64</span>%)]	Loss: <span class="number">0.756004</span></span><br><span class="line">Train: [<span class="number">44800</span>/<span class="number">60000</span> (<span class="number">75</span>%)]	Loss: <span class="number">0.723714</span></span><br><span class="line">Train: [<span class="number">51200</span>/<span class="number">60000</span> (<span class="number">85</span>%)]	Loss: <span class="number">0.438829</span></span><br><span class="line">Train: [<span class="number">57600</span>/<span class="number">60000</span> (<span class="number">96</span>%)]	Loss: <span class="number">0.474032</span></span><br><span class="line"></span><br><span class="line">Test <span class="built_in">set</span>: Average loss: <span class="number">0.5751</span>, Accuracy: <span class="number">8348</span>/<span class="number">10000</span> (<span class="number">83</span>%)</span><br></pre></td></tr></table></figure>

<p>在卷积神经网络上训练与测试：</p>
<p>In [0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">perm = torch.randperm(<span class="number">784</span>)</span><br><span class="line">n_features = <span class="number">6</span> <span class="comment"># number of feature maps</span></span><br><span class="line"></span><br><span class="line">model_cnn = CNN(input_size, n_features, output_size)</span><br><span class="line">model_cnn.to(device)</span><br><span class="line">optimizer = optim.SGD(model_cnn.parameters(), lr=<span class="number">0.01</span>, momentum=<span class="number">0.5</span>)</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Number of parameters: &#123;&#125;&#x27;</span>.<span class="built_in">format</span>(get_n_params(model_cnn)))</span><br><span class="line"></span><br><span class="line">train_perm(model_cnn, perm)</span><br><span class="line">test_perm(model_cnn, perm)</span><br></pre></td></tr></table></figure>

<p> Out[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">Number of parameters: <span class="number">6422</span></span><br><span class="line">Train: [<span class="number">0</span>/<span class="number">60000</span> (<span class="number">0</span>%)]	Loss: <span class="number">2.300903</span></span><br><span class="line">Train: [<span class="number">6400</span>/<span class="number">60000</span> (<span class="number">11</span>%)]	Loss: <span class="number">2.282535</span></span><br><span class="line">Train: [<span class="number">12800</span>/<span class="number">60000</span> (<span class="number">21</span>%)]	Loss: <span class="number">2.261807</span></span><br><span class="line">Train: [<span class="number">19200</span>/<span class="number">60000</span> (<span class="number">32</span>%)]	Loss: <span class="number">2.111837</span></span><br><span class="line">Train: [<span class="number">25600</span>/<span class="number">60000</span> (<span class="number">43</span>%)]	Loss: <span class="number">1.717916</span></span><br><span class="line">Train: [<span class="number">32000</span>/<span class="number">60000</span> (<span class="number">53</span>%)]	Loss: <span class="number">1.320999</span></span><br><span class="line">Train: [<span class="number">38400</span>/<span class="number">60000</span> (<span class="number">64</span>%)]	Loss: <span class="number">0.960259</span></span><br><span class="line">Train: [<span class="number">44800</span>/<span class="number">60000</span> (<span class="number">75</span>%)]	Loss: <span class="number">0.961738</span></span><br><span class="line">Train: [<span class="number">51200</span>/<span class="number">60000</span> (<span class="number">85</span>%)]	Loss: <span class="number">0.636504</span></span><br><span class="line">Train: [<span class="number">57600</span>/<span class="number">60000</span> (<span class="number">96</span>%)]	Loss: <span class="number">0.507474</span></span><br><span class="line"></span><br><span class="line">Test <span class="built_in">set</span>: Average loss: <span class="number">0.6227</span>, Accuracy: <span class="number">8003</span>/<span class="number">10000</span> (<span class="number">80</span>%)</span><br></pre></td></tr></table></figure>

<p>从打乱像素顺序的实验结果来看，全连接网络的性能基本上没有发生变化，因为混洗后的图像仍然保留了原始图像的统计特性。在许多情况下，图像中的像素排列并不会对图像的内容和语义产生重大影响。因此，全连接网络可以利用这些统计特性来识别和分类图像。</p>
<p>但是卷积神经网络的性能明显下降。对于这是因为卷积神经网络会利用像素的局部关系，但是打乱顺序以后，这些像素间的关系将无法得到利用。为了使CNN能够有效地学习和识别图像中的特征，保持像素的空间顺序是非常重要的。</p>
<h2 id="二、使用CNN对CIFAR10数据集分类"><a href="#二、使用CNN对CIFAR10数据集分类" class="headerlink" title="二、使用CNN对CIFAR10数据集分类"></a>二、使用CNN对CIFAR10数据集分类</h2><p>对于视觉数据，PyTorch 创建了一个叫做 totchvision 的包，该包含有支持加载类似Imagenet，CIFAR10，MNIST 等公共数据集的数据加载模块 torchvision.datasets 和支持加载图像数据数据转换模块 torch.utils.data.DataLoader。</p>
<p>下面将使用CIFAR10数据集，它包含十个类别：‘airplane’, ‘automobile’, ‘bird’, ‘cat’, ‘deer’, ‘dog’, ‘frog’, ‘horse’, ‘ship’, ‘truck’。CIFAR-10 中的图像尺寸为3x32x32，也就是RGB的3层颜色通道，每层通道内的尺寸为32*32。</p>
<p><img src="https://camo.githubusercontent.com/9c01c772a1597251f5722e32bc9dcfd28fd5a16b1b14ca943fb6af3ef3050ae3/687474703a2f2f7079746f7263686368696e612e636f6d2f77702d636f6e74656e742f75706c6f6164732f323031382f31322f636966617231302e706e67" alt="CIFAR10示例"></p>
<h3 id="1-加载数据并归一化"><a href="#1-加载数据并归一化" class="headerlink" title="1.加载数据并归一化"></a>1.加载数据并归一化</h3><p>首先，加载并归一化 CIFAR10 使用 torchvision 。torchvision 数据集的输出是范围在[0,1]之间的 PILImage，我们将他们转换成归一化范围为[-1,1]之间的张量 Tensors。</p>
<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用GPU训练，可以在菜单 &quot;代码执行工具&quot; -&gt; &quot;更改运行时类型&quot; 里进行设置</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"><span class="comment"># input[channel] = (input[channel] - mean[channel]) / std[channel]</span></span><br><span class="line"><span class="comment"># 这样就是：(（0,1）-0.5）/0.5=(-1,1)。标准化，分别表示R、G、B三个通道的均值和标准差。</span></span><br><span class="line">transform = transforms.Compose(</span><br><span class="line">    [transforms.ToTensor(),</span><br><span class="line">     transforms.Normalize((<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>), (<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.5</span>))])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 注意下面代码中：训练的 shuffle 是 True，测试的 shuffle 是 false</span></span><br><span class="line"><span class="comment"># 训练时可以打乱顺序增加多样性，测试是没有必要</span></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,</span><br><span class="line">                                        download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">64</span>,</span><br><span class="line">                                          shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">testset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>,</span><br><span class="line">                                       download=<span class="literal">True</span>, transform=transform)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">8</span>,</span><br><span class="line">                                         shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>Output[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Downloading https://www.cs.toronto.edu/~kriz/cifar-<span class="number">10</span>-python.tar.gz to ./data/cifar-<span class="number">10</span>-python.tar.gz</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">170498071</span>/<span class="number">170498071</span> [<span class="number">00</span>:<span class="number">13</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">13098026.41</span>it/s]</span><br><span class="line">Extracting ./data/cifar-<span class="number">10</span>-python.tar.gz to ./data</span><br><span class="line">Files already downloaded <span class="keyword">and</span> verified</span><br></pre></td></tr></table></figure>

<h3 id="2-接下来定义网络，损失函数和优化器："><a href="#2-接下来定义网络，损失函数和优化器：" class="headerlink" title="2.接下来定义网络，损失函数和优化器："></a>2.接下来定义网络，损失函数和优化器：</h3><p>定义一个简单的卷积神经网络CNN模型，其中包含了卷积层、池化层和全连接层。</p>
<p>其中，<code>nn.Conv2d</code>：定义了两个卷积层，分别为<code>conv1</code>和<code>conv2</code>。<code>conv1</code>的输入通道数为3，输出通道数为6，卷积核大小为5x5。<code>conv2</code>的输入通道数为6，输出通道数为16，卷积核大小为5x5。<code>nn.MaxPool2d</code>：定义了一个最大池化层<code>pool</code>，池化核大小为2x2，步幅为2。这个池化层用于对特征图进行下采样，减少特征图的尺寸和参数数量。</p>
<p><code>nn.Linear</code>：定义了三个全连接层，分别为<code>fc1</code>、<code>fc2</code>和<code>fc3</code>。<code>fc1</code>的输入大小为16x5x5，输出大小为120；<code>fc2</code>的输入大小为120，输出大小为84；<code>fc3</code>的输入大小为84，输出大小为10。</p>
<p><code>nn.CrossEntropyLoss()</code>：定义了交叉熵损失函数，用于计算模型输出和真实标签之间的损失。</p>
<p><code>optim.Adam(net.parameters(), lr=0.001)</code>：定义了优化器，使用Adam算法对网络参数进行优化，学习率为0.001。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Net</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(Net, self).__init__()</span><br><span class="line">        <span class="comment"># 彩色图片为RGB三通道，因此第一个卷积层输入通道数为3</span></span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">3</span>, <span class="number">6</span>, <span class="number">5</span>)</span><br><span class="line">        self.pool = nn.MaxPool2d(<span class="number">2</span>, <span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">6</span>, <span class="number">16</span>, <span class="number">5</span>)</span><br><span class="line">        self.fc1 = nn.Linear(<span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>, <span class="number">120</span>)</span><br><span class="line">        self.fc2 = nn.Linear(<span class="number">120</span>, <span class="number">84</span>)</span><br><span class="line">        self.fc3 = nn.Linear(<span class="number">84</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        x = self.pool(F.relu(self.conv1(x)))</span><br><span class="line">        x = self.pool(F.relu(self.conv2(x)))</span><br><span class="line">        x = x.view(-<span class="number">1</span>, <span class="number">16</span> * <span class="number">5</span> * <span class="number">5</span>)</span><br><span class="line">        x = F.relu(self.fc1(x))</span><br><span class="line">        x = F.relu(self.fc2(x))</span><br><span class="line">        x = self.fc3(x)</span><br><span class="line">        <span class="keyword">return</span> x</span><br><span class="line"></span><br><span class="line"><span class="comment"># 网络放到GPU上</span></span><br><span class="line">net = Net().to(device)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line"><span class="comment"># 优化器定义位置与任务一中优化器定义位置不同</span></span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-训练模型"><a href="#3-训练模型" class="headerlink" title="3.训练模型"></a>3.训练模型</h3><p>在每次训练迭代中，首先使用<code>optimizer.zero_grad()</code>将优化器的梯度归零，然后使用<code>net(inputs)</code>进行正向传播计算输出，使用<code>loss = criterion(outputs, labels)</code>计算损失，接着使用<code>loss.backward()</code>进行反向传播计算梯度，并最后通过<code>optimizer.step()</code>方法执行参数更新。这个训练过程适用于使用Adam优化器进行训练。</p>
<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  <span class="comment"># 重复多轮训练</span></span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        <span class="comment"># 优化器梯度归零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 正向传播 +　反向传播 + 优化</span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 输出统计信息</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch: %d Minibatch: %5d loss: %.3f&#x27;</span> %(epoch + <span class="number">1</span>, i + <span class="number">1</span>, loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>Output[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br></pre></td><td class="code"><pre><span class="line">Epoch: <span class="number">1</span> Minibatch:     <span class="number">1</span> loss: <span class="number">2.309</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">101</span> loss: <span class="number">1.914</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.807</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.600</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">401</span> loss: <span class="number">1.581</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">501</span> loss: <span class="number">1.565</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">601</span> loss: <span class="number">1.566</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">701</span> loss: <span class="number">1.560</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:     <span class="number">1</span> loss: <span class="number">1.365</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">101</span> loss: <span class="number">1.678</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.356</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.395</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">401</span> loss: <span class="number">1.388</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">501</span> loss: <span class="number">1.404</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">601</span> loss: <span class="number">1.481</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">701</span> loss: <span class="number">1.396</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:     <span class="number">1</span> loss: <span class="number">1.304</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">101</span> loss: <span class="number">1.481</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.193</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.147</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">401</span> loss: <span class="number">1.362</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">501</span> loss: <span class="number">1.467</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">601</span> loss: <span class="number">1.368</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">701</span> loss: <span class="number">1.301</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:     <span class="number">1</span> loss: <span class="number">1.435</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">101</span> loss: <span class="number">1.414</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.072</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.171</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">401</span> loss: <span class="number">1.183</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">501</span> loss: <span class="number">1.017</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">601</span> loss: <span class="number">1.166</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">701</span> loss: <span class="number">1.196</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:     <span class="number">1</span> loss: <span class="number">1.203</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.877</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.032</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.188</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">401</span> loss: <span class="number">1.120</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">501</span> loss: <span class="number">0.961</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">601</span> loss: <span class="number">1.008</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">701</span> loss: <span class="number">0.815</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.862</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">101</span> loss: <span class="number">1.005</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.268</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.011</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">401</span> loss: <span class="number">1.175</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">501</span> loss: <span class="number">0.913</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">601</span> loss: <span class="number">0.918</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">701</span> loss: <span class="number">1.017</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.846</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.793</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.206</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.090</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">401</span> loss: <span class="number">0.988</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">501</span> loss: <span class="number">0.961</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">601</span> loss: <span class="number">0.955</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">701</span> loss: <span class="number">0.704</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.869</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.850</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.882</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.825</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">401</span> loss: <span class="number">0.759</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">501</span> loss: <span class="number">1.146</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">601</span> loss: <span class="number">0.935</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">701</span> loss: <span class="number">1.235</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.810</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">101</span> loss: <span class="number">1.108</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">201</span> loss: <span class="number">1.074</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">301</span> loss: <span class="number">1.122</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">401</span> loss: <span class="number">0.990</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">501</span> loss: <span class="number">0.872</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">601</span> loss: <span class="number">0.791</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">701</span> loss: <span class="number">1.023</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.888</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.733</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.845</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.800</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">401</span> loss: <span class="number">0.956</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">501</span> loss: <span class="number">0.847</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">601</span> loss: <span class="number">0.595</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">701</span> loss: <span class="number">0.978</span></span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure>

<h3 id="4-测试模型性能"><a href="#4-测试模型性能" class="headerlink" title="4.测试模型性能"></a>4.测试模型性能</h3><p>Inp[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">    images, labels = data</span><br><span class="line">    images, labels = images.to(device), labels.to(device)</span><br><span class="line">    outputs = net(images)</span><br><span class="line">    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">    total += labels.size(<span class="number">0</span>)</span><br><span class="line">    correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy of the network on the 10000 test images: %d %%&#x27;</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>

<p>Output[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy of the network on the <span class="number">10000</span> test images: <span class="number">62</span> %</span><br></pre></td></tr></table></figure>



<h2 id="三、使用-VGG16-对-CIFAR10-分类"><a href="#三、使用-VGG16-对-CIFAR10-分类" class="headerlink" title="三、使用 VGG16 对 CIFAR10 分类"></a>三、使用 VGG16 对 CIFAR10 分类</h2><h3 id="1-定义-dataloader"><a href="#1-定义-dataloader" class="headerlink" title="1. 定义 dataloader"></a>1. 定义 dataloader</h3><p>需要注意的是，这里的 transform，dataloader 和之前定义的有所不同，对测试集以及训练集分开处理，<code>transforms.RandomCrop(32, padding=4)</code>: 在随机位置对图像进行裁剪，裁剪后的图像大小为32x32。<code>padding=4</code>表示在图像周围添加4个像素，然后再进行随机裁剪，这样可以增加数据的多样性。<code>transforms.RandomHorizontalFlip()</code>: 随机水平翻转图像。这也是一种数据增强技术，可以增加数据的多样性。<code>transforms.ToTensor()</code>: 将图像转换为张量（Tensor）格式，便于在PyTorch中处理。<code>transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))</code>: 对图像进行标准化处理。这里的均值和标准差是CIFAR-10数据集的RGB图像通道的均值和标准差。标准化可以使得数据在训练过程中更容易收敛，并且提高了模型的训练效率。</p>
<p><code>transform=transform_train</code>表示对训练数据集应用之前定义好的<code>transform_train</code>数据预处理操作，包括图像的随机裁剪、水平翻转和标准化等。<code>batch_size=128</code>表示每次从数据集中加载的批量大小。这里设置为<code>128</code>，意味着每次训练或测试时会加载128张图像。<code>shuffle=True</code>表示在每个epoch内是否对训练数据进行洗牌。在训练阶段，我们一般需要对训练数据进行洗牌，以确保样本的随机性和多样性，因此设置为<code>True</code>。</p>
<p>In [0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision</span><br><span class="line"><span class="keyword">import</span> torchvision.transforms <span class="keyword">as</span> transforms</span><br><span class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> torch.nn <span class="keyword">as</span> nn</span><br><span class="line"><span class="keyword">import</span> torch.nn.functional <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">import</span> torch.optim <span class="keyword">as</span> optim</span><br><span class="line"></span><br><span class="line"><span class="comment"># 使用GPU训练，可以在菜单 &quot;代码执行工具&quot; -&gt; &quot;更改运行时类型&quot; 里进行设置</span></span><br><span class="line">device = torch.device(<span class="string">&quot;cuda:0&quot;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&quot;cpu&quot;</span>)</span><br><span class="line"></span><br><span class="line">transform_train = transforms.Compose([</span><br><span class="line">    transforms.RandomCrop(<span class="number">32</span>, padding=<span class="number">4</span>),</span><br><span class="line">    transforms.RandomHorizontalFlip(),</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), (<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>))])</span><br><span class="line"></span><br><span class="line">transform_test = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">    transforms.Normalize((<span class="number">0.4914</span>, <span class="number">0.4822</span>, <span class="number">0.4465</span>), (<span class="number">0.2023</span>, <span class="number">0.1994</span>, <span class="number">0.2010</span>))])</span><br><span class="line"></span><br><span class="line">trainset = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">True</span>,  download=<span class="literal">True</span>, transform=transform_train)</span><br><span class="line">testset  = torchvision.datasets.CIFAR10(root=<span class="string">&#x27;./data&#x27;</span>, train=<span class="literal">False</span>, download=<span class="literal">True</span>, transform=transform_test)</span><br><span class="line"></span><br><span class="line">trainloader = torch.utils.data.DataLoader(trainset, batch_size=<span class="number">128</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">2</span>)</span><br><span class="line">testloader = torch.utils.data.DataLoader(testset, batch_size=<span class="number">128</span>, shuffle=<span class="literal">False</span>, num_workers=<span class="number">2</span>)</span><br><span class="line"></span><br><span class="line">classes = (<span class="string">&#x27;plane&#x27;</span>, <span class="string">&#x27;car&#x27;</span>, <span class="string">&#x27;bird&#x27;</span>, <span class="string">&#x27;cat&#x27;</span>,</span><br><span class="line">           <span class="string">&#x27;deer&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;frog&#x27;</span>, <span class="string">&#x27;horse&#x27;</span>, <span class="string">&#x27;ship&#x27;</span>, <span class="string">&#x27;truck&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>Output[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Downloading https://www.cs.toronto.edu/~kriz/cifar-<span class="number">10</span>-python.tar.gz to ./data/cifar-<span class="number">10</span>-python.tar.gz</span><br><span class="line"><span class="number">100</span>%|██████████| <span class="number">170498071</span>/<span class="number">170498071</span> [<span class="number">00</span>:<span class="number">13</span>&lt;<span class="number">00</span>:<span class="number">00</span>, <span class="number">12866169.70</span>it/s]</span><br><span class="line">Extracting ./data/cifar-<span class="number">10</span>-python.tar.gz to ./data</span><br><span class="line">Files already downloaded <span class="keyword">and</span> verified</span><br></pre></td></tr></table></figure>

<h3 id="2-简化的VGG网络结构"><a href="#2-简化的VGG网络结构" class="headerlink" title="2.简化的VGG网络结构"></a>2.简化的VGG网络结构</h3><p>由构造方法中的配置变量<code>cfg</code>与<code>_make_layers</code>方法构造VGG网络，网络结构如下：</p>
<ol>
<li>输入图像的通道数为3（RGB图像）。</li>
<li>使用一系列的卷积层和池化层构建特征提取部分，具体结构为：64个3x3卷积层，2x2最大池化层，128个3x3卷积层，2x2最大池化层，256个3x3卷积层，256个3x3卷积层，2x2最大池化层，512个3x3卷积层，512个3x3卷积层，2x2最大池化层，512个3x3卷积层，512个3x3卷积层，2x2最大池化层。</li>
<li>使用一个1x1的平均池化层将特征进行降维，使得特征图的大小变成1x1。</li>
<li>最后通过一个全连接层将特征映射到10个类别（在这个例子中，输出类别数为10）。</li>
</ol>
<p>该VGG网络在构造深度的同时，通过使用小尺寸的卷积核和池化层，有效地增加了网络的宽度，使得网络能够捕捉更多的特征信息。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">VGG</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(VGG, self).__init__()</span><br><span class="line">        self.cfg = [<span class="number">64</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">128</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">256</span>, <span class="number">256</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>, <span class="number">512</span>, <span class="number">512</span>, <span class="string">&#x27;M&#x27;</span>]</span><br><span class="line">        self.features = self._make_layers(self.cfg)</span><br><span class="line">        self.classifier = nn.Linear(<span class="number">512</span>, <span class="number">10</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x</span>):</span><br><span class="line">        out = self.features(x)</span><br><span class="line">        out = out.view(out.size(<span class="number">0</span>), -<span class="number">1</span>)</span><br><span class="line">        out = self.classifier(out)</span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_make_layers</span>(<span class="params">self, cfg</span>):</span><br><span class="line">        layers = []</span><br><span class="line">        in_channels = <span class="number">3</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> cfg:</span><br><span class="line">            <span class="keyword">if</span> x == <span class="string">&#x27;M&#x27;</span>:</span><br><span class="line">                layers += [nn.MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>)]</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                layers += [nn.Conv2d(in_channels, x, kernel_size=<span class="number">3</span>, padding=<span class="number">1</span>),</span><br><span class="line">                           nn.BatchNorm2d(x),</span><br><span class="line">                           nn.ReLU(inplace=<span class="literal">True</span>)]</span><br><span class="line">                in_channels = x</span><br><span class="line">        layers += [nn.AvgPool2d(kernel_size=<span class="number">1</span>, stride=<span class="number">1</span>)]</span><br><span class="line">        <span class="keyword">return</span> nn.Sequential(*layers)</span><br></pre></td></tr></table></figure>

<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 网络放到GPU上</span></span><br><span class="line">net = VGG().to(device)</span><br><span class="line">criterion = nn.CrossEntropyLoss()</span><br><span class="line">optimizer = optim.Adam(net.parameters(), lr=<span class="number">0.001</span>)</span><br></pre></td></tr></table></figure>

<h3 id="3-模型训练及性能测试"><a href="#3-模型训练及性能测试" class="headerlink" title="3.模型训练及性能测试"></a>3.模型训练及性能测试</h3><p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">10</span>):  <span class="comment"># 重复多轮训练</span></span><br><span class="line">    <span class="keyword">for</span> i, (inputs, labels) <span class="keyword">in</span> <span class="built_in">enumerate</span>(trainloader):</span><br><span class="line">        inputs = inputs.to(device)</span><br><span class="line">        labels = labels.to(device)</span><br><span class="line">        <span class="comment"># 优化器梯度归零</span></span><br><span class="line">        optimizer.zero_grad()</span><br><span class="line">        <span class="comment"># 正向传播 +　反向传播 + 优化 </span></span><br><span class="line">        outputs = net(inputs)</span><br><span class="line">        loss = criterion(outputs, labels)</span><br><span class="line">        loss.backward()</span><br><span class="line">        optimizer.step()</span><br><span class="line">        <span class="comment"># 输出统计信息</span></span><br><span class="line">        <span class="keyword">if</span> i % <span class="number">100</span> == <span class="number">0</span>:   </span><br><span class="line">            <span class="built_in">print</span>(<span class="string">&#x27;Epoch: %d Minibatch: %5d loss: %.3f&#x27;</span> %(epoch + <span class="number">1</span>, i + <span class="number">1</span>, loss.item()))</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Finished Training&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>Output[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">Epoch: <span class="number">1</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.407</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.479</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.398</span></span><br><span class="line">Epoch: <span class="number">1</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.260</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.426</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.288</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.312</span></span><br><span class="line">Epoch: <span class="number">2</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.339</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.250</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.289</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.372</span></span><br><span class="line">Epoch: <span class="number">3</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.313</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.298</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.288</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.293</span></span><br><span class="line">Epoch: <span class="number">4</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.277</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.188</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.251</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.313</span></span><br><span class="line">Epoch: <span class="number">5</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.343</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.180</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.277</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.200</span></span><br><span class="line">Epoch: <span class="number">6</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.347</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.211</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.309</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.213</span></span><br><span class="line">Epoch: <span class="number">7</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.202</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.171</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.314</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.149</span></span><br><span class="line">Epoch: <span class="number">8</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.265</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.280</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.248</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.152</span></span><br><span class="line">Epoch: <span class="number">9</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.154</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:     <span class="number">1</span> loss: <span class="number">0.201</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">101</span> loss: <span class="number">0.103</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">201</span> loss: <span class="number">0.200</span></span><br><span class="line">Epoch: <span class="number">10</span> Minibatch:   <span class="number">301</span> loss: <span class="number">0.326</span></span><br><span class="line">Finished Training</span><br></pre></td></tr></table></figure>

<p>In[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">correct = <span class="number">0</span></span><br><span class="line">total = <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> data <span class="keyword">in</span> testloader:</span><br><span class="line">    images, labels = data</span><br><span class="line">    images, labels = images.to(device), labels.to(device)</span><br><span class="line">    outputs = net(images)</span><br><span class="line">    _, predicted = torch.<span class="built_in">max</span>(outputs.data, <span class="number">1</span>)</span><br><span class="line">    total += labels.size(<span class="number">0</span>)</span><br><span class="line">    correct += (predicted == labels).<span class="built_in">sum</span>().item()</span><br><span class="line"></span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;Accuracy of the network on the 10000 test images: %.2f %%&#x27;</span> % (</span><br><span class="line">    <span class="number">100</span> * correct / total))</span><br></pre></td></tr></table></figure>

<p>Output[0]:</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Accuracy of the network on the <span class="number">10000</span> test images: <span class="number">86.58</span> %</span><br></pre></td></tr></table></figure>

<p>可以看到，使用一个简化版的 VGG 网络，就能够显著地将准确率由 62%，提升到 86.58%</p>
<h2 id="四、问题"><a href="#四、问题" class="headerlink" title="四、问题"></a>四、问题</h2><h3 id="1、dataloader-里面-shuffle-取不同值有什么区别？"><a href="#1、dataloader-里面-shuffle-取不同值有什么区别？" class="headerlink" title="1、dataloader 里面 shuffle 取不同值有什么区别？"></a><strong>1、dataloader 里面 shuffle 取不同值有什么区别？</strong></h3><p>在使用 PyTorch 中的 DataLoader 时，shuffle 参数用于指定数据是否在每个 epoch（一个完整的数据集遍历）之前进行打乱。</p>
<p>当 <code>shuffle=True</code> 时，每个 epoch 开始之前会对数据进行<strong>随机打乱</strong>。这样可以在每个 epoch 中随机地呈现样本，增加数据的多样性，有助于提高模型的泛化能力和稳定性。</p>
<p>当 <code>shuffle=False</code> 时，数据将按照原始顺序传递给模型。这意味着每个 epoch 中的样本顺序都是固定的，模型将以相同的顺序处理数据。这在某些情况下可能是有用的，例如需要确保在不同模型或训练过程中对同一数据进行比较时保持一致性。</p>
<p>因此，<code>shuffle</code> 参数的取值会影响数据在每个 epoch 中的呈现顺序。如果希望每个 epoch 中的数据顺序随机化，以增加模型的泛化能力，可以将 <code>shuffle=True</code>；如果希望每个 epoch 中的数据顺序保持一致，可以将 <code>shuffle=False</code>。选择合适的取值取决于具体的任务和需求。</p>
<h3 id="2、transform-里，取了不同值，这个有什么区别？"><a href="#2、transform-里，取了不同值，这个有什么区别？" class="headerlink" title="2、transform 里，取了不同值，这个有什么区别？"></a><strong>2、transform 里，取了不同值，这个有什么区别？</strong></h3><p>在 PyTorch 的数据预处理中，可以使用 torchvision.transforms 模块中的各种转换函数来对数据进行处理。这些转换函数可以在数据加载之前或之后应用于数据。</p>
<p>取不同的转换函数会产生不同的数据处理效果和结果。下面是一些常见的转换函数及其作用：</p>
<ol>
<li>ToTensor(): 将 PIL 图像或 ndarray 转换为 Tensor 格式，并进行归一化。这个转换函数通常用于将图像数据转换为神经网络的输入格式。</li>
<li>Normalize(mean, std): 标准化图像数据，通过减去均值(mean)并除以标准差(std)来进行归一化。这个转换函数通常用于处理图像数据的亮度和对比度。</li>
<li>Resize(size)：调整图像大小为指定的 size。可以是一个整数，表示调整图像的较短边为该长度，较长边按比例调整；也可以是一个元组 (height, width)，表示调整图像的尺寸为指定的高度和宽度。</li>
<li>RandomCrop(size)：随机裁剪图像为指定的 size。可以是一个整数，表示裁剪出的图像的边长为该长度，裁剪位置随机选择；也可以是一个元组 (height, width)，表示裁剪出的图像尺寸为指定的高度和宽度。</li>
<li>RandomHorizontalFlip(p)：以概率 p 随机水平翻转图像。通常用于数据增强，增加数据的多样性。</li>
</ol>
<p>这只是一小部分常见的转换函数，还有其他许多可用的转换函数。通过选择不同的转换函数及其参数，可以对数据进行不同的处理，以满足具体任务的需求。具体选择哪些转换函数取决于数据的特点和模型的要求。</p>
<h3 id="3、epoch-和-batch-的区别？"><a href="#3、epoch-和-batch-的区别？" class="headerlink" title="3、epoch 和 batch 的区别？"></a><strong>3、epoch 和 batch 的区别？</strong></h3><ul>
<li>Epoch（迭代）：Epoch 是指将整个训练数据集完整地通过神经网络进行一次正向传播和反向传播的过程。在每个 epoch 中，将所有的训练样本都传递给网络进行训练，并根据损失函数计算梯度进行参数更新。<strong>一个 epoch 的完成意味着整个训练集的所有样本都被用于训练</strong>。</li>
<li>Batch（批次）：Batch 是指每次迭代时所使用的一小部分训练样本。由于在训练过程中处理整个数据集可能会占用大量的内存和计算资源，因此通常将训练数据分成多个批次进行处理。每个批次中的样本被一起输入到神经网络中进行正向传播和反向传播，以计算梯度和更新参数。</li>
</ul>
<p>在训练过程中，通常会将数据集分成多个批次，通过多次迭代的方式将所有批次的数据都传递给神经网络。每个批次的样本数量可以根据具体情况进行选择，常见的批次大小为 8、16、32、64 等。选择合适的批次大小可以在充分利用计算资源的同时，加速训练过程并提高模型的泛化能力。</p>
<p>因此，epoch 是指整个训练数据集通过网络一次训练的过程，而 batch 是指每次迭代训练中所使用的一小部分样本。通过多次迭代，逐渐更新参数并降低损失函数，以提高模型的性能。</p>
<h3 id="4、1x1的卷积和-FC-有什么区别？主要起什么作用？"><a href="#4、1x1的卷积和-FC-有什么区别？主要起什么作用？" class="headerlink" title="4、1x1的卷积和 FC 有什么区别？主要起什么作用？"></a><strong>4、1x1的卷积和 FC 有什么区别？主要起什么作用？</strong></h3><p>1x1卷积是指卷积核的尺寸为1x1的卷积操作，它在卷积神经网络中常被用作降维和增加非线性的操作。1x1卷积通过对输入特征图的每个像素点进行线性组合和非线性激活，生成输出特征图。1x1卷积的操作是在空间维度上进行的，仅对输入特征图的通道进行卷积运算，它只对输入特征图的通道进行线性组合。1x1卷积的主要作用是通过改变通道数来调整特征图的深度。它可以起到增加或减少特征图通道数的作用，从而控制模型的复杂度和参数量。1x1卷积还可以进行特征图的融合和信息交互，通过学习通道之间的权重，实现特征的组合和选择性地增强或抑制某些特征。</p>
<p>全连接层将输入特征展平为一维向量，并将其与权重矩阵相乘，再加上偏置项，经过非线性激活函数得到输出。全连接层的主要作用是在神经网络中建立不同层之间的连接，将前一层的特征映射与后一层的神经元相连，实现特征的组合和转换。全连接层的操作是在特征维度上进行的，将整个特征向量与权重矩阵相乘得到输出向量。全连接层在图像分类和生成模型等任务中经常被用作最后一层，用于将高维特征转化为类别概率或生成样本的特征向量。</p>
<h3 id="5、residual-leanring-为什么能够提升准确率？"><a href="#5、residual-leanring-为什么能够提升准确率？" class="headerlink" title="5、residual leanring 为什么能够提升准确率？"></a><strong>5、residual leanring 为什么能够提升准确率？</strong></h3><ol>
<li>缓解梯度消失问题：在深层神经网络中，梯度消失是一个常见的问题，导致在反向传播过程中梯度逐渐变小，难以更新浅层网络的参数。通过引入残差连接，即跳跃连接（shortcut connection），可以直接将输入特征传递到后续层，绕过一部分卷积层的操作。这样，即使梯度在深层网络中逐渐减小，原始输入信息仍然可以通过跳跃连接直接传递到后续层，从而保持梯度的有效传播。这缓解了梯度消失问题，使得深层网络更容易训练。</li>
<li>学习残差映射：通过残差连接，模型可以学习到残差映射，即目标特征与输入特征之间的差异。相比于直接学习目标映射，学习残差映射更容易优化。因为残差映射可以更好地逼近恒等映射（identity mapping），即使模型的学习目标是将输入特征映射到与目标特征相同的空间，残差映射能够更快速地收敛。这样，模型可以更容易地学习到目标特征的细微变化，从而提高了准确率。</li>
</ol>
<p>总结起来，残差学习通过引入跳跃连接和学习残差映射的方式，缓解了梯度消失问题并提高了优化效率。这使得深层网络更易于训练，并能够更好地逼近目标映射，从而提升了准确率。</p>
<h3 id="6、代码练习二里，网络和1989年-Lecun-提出的-LeNet-有什么区别？"><a href="#6、代码练习二里，网络和1989年-Lecun-提出的-LeNet-有什么区别？" class="headerlink" title="6、代码练习二里，网络和1989年 Lecun 提出的 LeNet 有什么区别？"></a><strong>6、代码练习二里，网络和1989年 Lecun 提出的 LeNet 有什么区别？</strong></h3><ol>
<li>输入通道数不同：LeNet-1最初用于手写数字识别，因此输入通道数为1（灰度图像）。而这个网络用于彩色图片，输入通道数为3（RGB三通道）。</li>
<li>卷积核个数不同：在这个网络中，第一个卷积层的卷积核个数为6，第二个卷积层的卷积核个数为16。而 LeNet-1 中的卷积核个数不同，具体是4个和12个。</li>
<li>池化方式不同：这个网络使用了MaxPooling进行池化，即取局部区域的最大值。而 LeNet 使用的是AveragePooling，取局部区域的平均值。</li>
<li>全连接层的神经元个数不同：这个网络中，第一个全连接层有120个神经元，第二个全连接层有84个神经元，第三个全连接层有10个神经元，而 LeNet -1中仅含一个全连接层，神经元个数为10。</li>
</ol>
<h3 id="7、代码练习二里，卷积以后feature-map-尺寸会变小，如何应用-Residual-Learning"><a href="#7、代码练习二里，卷积以后feature-map-尺寸会变小，如何应用-Residual-Learning" class="headerlink" title="7、代码练习二里，卷积以后feature map 尺寸会变小，如何应用 Residual Learning?"></a><strong>7、代码练习二里，卷积以后feature map 尺寸会变小，如何应用 Residual Learning?</strong></h3><p>在卷积神经网络中，通常在网络中间会存在多个卷积层。每经过一个卷积层，feature map 的尺寸通常会减小，这是由于卷积操作中的边缘填充和步幅设置所引起的。</p>
<p>在应用Residual Learning时，通常会使用跳跃连接来绕过一部分卷积层，使得输出可以直接连接到后面的层，而不仅仅是通过一系列卷积层的堆叠。这样做的目的是让网络在学习特征的过程中，能够更加灵活地选择是否要保留之前层的特征信息。</p>
<p>在残差块中，输入<code>x</code>经过一系列的卷积和非线性激活函数后得到了特征<code>F(x)</code>，然后<code>F(x)</code>与输入<code>x</code>相加，得到残差<code>R(x)=F(x)+x</code>。最后，通过非线性激活函数（如ReLU）来处理残差，得到最终的输出<code>y</code>。这个过程可以表示为：</p>
<p><em>y</em>&#x3D;ReLU(<em>R</em>(<em>x</em>))</p>
<p>如果输<code>x</code>和输出<code>y</code>的维度不同，可以通过引入额外的全连接层或卷积层来调整维度。通过这种方式，残差网络可以在学习特征时更加高效，因为它不是直接学习输入到输出的映射，而是学习残差的映射，这样网络可以更容易地优化和训练。</p>
<h3 id="8、有什么方法可以进一步提升准确率？"><a href="#8、有什么方法可以进一步提升准确率？" class="headerlink" title="8、有什么方法可以进一步提升准确率？"></a><strong>8、有什么方法可以进一步提升准确率？</strong></h3><ol>
<li>更深的网络：增加网络的深度可以提高网络的表达能力，使其能够学习更复杂的特征和模式。但要注意避免梯度消失和过拟合问题，可以采用Residual Learning等技术来解决。</li>
<li>更大的卷积核和更多的卷积层：使用更大的卷积核可以捕捉更广泛的特征，而增加卷积层的数量可以提高网络的感受野，进而增强特征提取能力。</li>
<li>数据增强：通过对训练数据进行随机变换（如翻转、旋转、平移、缩放等），可以扩充训练数据集，增加模型的泛化能力。</li>
<li>Batch Normalization：使用Batch Normalization层可以加速网络的收敛，使得网络对参数初始化和学习率设置不敏感，从而更容易训练。</li>
<li>Dropout：引入Dropout层可以随机地将一些神经元的输出置零，防止过拟合，增加网络的泛化能力。</li>
<li>学习率调度：使用学习率调度策略，随着训练的进行逐渐减小学习率，可以帮助网络更好地收敛。</li>
<li>模型集成：将多个训练好的模型进行集成，如投票、平均等方式，可以提高模型的泛化能力。</li>
<li>转移学习：使用预训练的模型（如在ImageNet上预训练的模型）作为初始化参数，然后在新的数据集上进行微调，可以加速训练过程并提高准确率。</li>
<li>使用不同的优化器：尝试不同的优化器（如Adam、SGD、RMSprop等），有时不同的优化器在不同的任务上表现更好。</li>
<li>参数调优：对网络的超参数进行调优，包括学习率、正则化项、网络结构等。</li>
</ol>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://example.com/2023/07/18/CNN/" data-id="clk80e8g900004suod9etbes3" data-title="CNN" class="article-share-link"><span class="fa fa-share">Share</span></a>
      
      
      
    </footer>
  </div>
  
    
<nav id="article-nav">
  
  
    <a href="/2023/07/13/DL/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">DL</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    

  
    

  
    
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/07/">July 2023</a></li></ul>
    </div>
  </div>


  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2023/07/18/CNN/">CNN</a>
          </li>
        
          <li>
            <a href="/2023/07/13/DL/">DL</a>
          </li>
        
          <li>
            <a href="/2023/07/13/hello-world/">Hello World</a>
          </li>
        
      </ul>
    </div>
  </div>

  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2023 John Doe<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.6.4.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>